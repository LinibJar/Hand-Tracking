{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a89019f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mediapipe\n",
      "  Downloading mediapipe-0.8.4.2-cp38-cp38-win_amd64.whl (52.0 MB)\n",
      "Requirement already satisfied: wheel in e:\\face mask detection transfer learning\\venv\\lib\\site-packages (from mediapipe) (0.36.2)\n",
      "Requirement already satisfied: absl-py in e:\\face mask detection transfer learning\\venv\\lib\\site-packages (from mediapipe) (0.12.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in e:\\face mask detection transfer learning\\venv\\lib\\site-packages (from mediapipe) (21.2.0)\n",
      "Collecting opencv-contrib-python\n",
      "  Downloading opencv_contrib_python-4.5.2.52-cp38-cp38-win_amd64.whl (41.5 MB)\n",
      "Requirement already satisfied: numpy in e:\\face mask detection transfer learning\\venv\\lib\\site-packages (from mediapipe) (1.19.5)\n",
      "Requirement already satisfied: six in e:\\face mask detection transfer learning\\venv\\lib\\site-packages (from mediapipe) (1.15.0)\n",
      "Requirement already satisfied: protobuf>=3.11.4 in e:\\face mask detection transfer learning\\venv\\lib\\site-packages (from mediapipe) (3.17.1)\n",
      "Installing collected packages: opencv-contrib-python, mediapipe\n",
      "Successfully installed mediapipe-0.8.4.2 opencv-contrib-python-4.5.2.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.1.1; however, version 21.1.2 is available.\n",
      "You should consider upgrading via the 'e:\\face mask detection transfer learning\\venv\\scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install mediapipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201d6a71",
   "metadata": {},
   "source": [
    "# Importing Necessary Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e84b5461",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56ee55f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acdff33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpHands = mp.solutions.hands  #palm detection using mediapipe\n",
    "hands = mpHands.Hands()       #getting hand instances\n",
    "mpDraw = mp.solutions.drawing_utils #drawing landmarks\n",
    "pTime = 0                            #previous time\n",
    "cTime=0                              #current time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f916adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    success,img = cap.read(1)\n",
    "    imgRGB = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(imgRGB)\n",
    "#     print(results.multi_hand_landmarks)\n",
    "    if results.multi_hand_landmarks:\n",
    "        for handLms in results.multi_hand_landmarks:\n",
    "            mpDraw.draw_landmarks(img,handLms,mpHands.HAND_CONNECTIONS)\n",
    "    cTime = time.time()\n",
    "    fps = 1/(cTime-pTime)\n",
    "    pTime = cTime\n",
    "    \n",
    "    cv2.putText(img,int(fps),(10,70),cv2.FONT_HERSHEY_PLAIN,3,(255,0,255),3)\n",
    "        \n",
    "    cv2.imshow(\"Image\",img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "          break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee0fd887",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.2) C:\\Users\\runneradmin\\AppData\\Local\\Temp\\pip-req-build-kuwfz3h3\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-1d65249651e4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0msuccess\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mimgRGB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhands\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgRGB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m#     print(results.multi_hand_landmarks)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.2) C:\\Users\\runneradmin\\AppData\\Local\\Temp\\pip-req-build-kuwfz3h3\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "mpHands = mp.solutions.hands  #palm detection using mediapipe\n",
    "hands = mpHands.Hands()       #getting hand instances\n",
    "mpDraw = mp.solutions.drawing_utils #drawing landmarks\n",
    "pTime = 0                            #previous time\n",
    "cTime=0                              #current time\n",
    "\n",
    "while True:\n",
    "    success,img = cap.read(1)\n",
    "    imgRGB = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(imgRGB)\n",
    "#     print(results.multi_hand_landmarks)\n",
    "    if results.multi_hand_landmarks:\n",
    "        for handLms in results.multi_hand_landmarks:\n",
    "            for id,lm in enumerate(handLms.landmark):\n",
    "                h,w,c = img.shape\n",
    "                cx,cy = int(lm.x*w),int(lm.y*h)\n",
    "#                 print(id,cx,cy)\n",
    "                if id==8:\n",
    "                    cv2.circle(img,(cx,cy),15,(255,0,255),cv2.FILLED)\n",
    "\n",
    "                    \n",
    "            mpDraw.draw_landmarks(img,handLms,mpHands.HAND_CONNECTIONS)\n",
    "    cTime = time.time()\n",
    "    fps = int(1/(cTime-pTime))\n",
    "    pTime = cTime\n",
    "    \n",
    "    cv2.putText(img,str(fps),(10,70),cv2.FONT_HERSHEY_PLAIN,3,(255,0,255),3)\n",
    "    img = cv2.flip(img,1)  \n",
    "    cv2.imshow(\"Image\",img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "          break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c29d999",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-573518380a3c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0msuccess\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[0mimgRGB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhands\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgRGB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "from ctypes import cast, POINTER\n",
    "from comtypes import CLSCTX_ALL\n",
    "from pycaw.pycaw import AudioUtilities, IAudioEndpointVolume\n",
    "devices = AudioUtilities.GetSpeakers()\n",
    "interface = devices.Activate(IAudioEndpointVolume._iid_, CLSCTX_ALL, None)\n",
    "volume = cast(interface, POINTER(IAudioEndpointVolume))\n",
    "volume.GetMute()\n",
    "volume.GetMasterVolumeLevel()\n",
    "volume.GetVolumeRange()\n",
    "cap = cv2.VideoCapture(0)\n",
    "distance = 0\n",
    "mpHands = mp.solutions.hands  #palm detection using mediapipe\n",
    "hands = mpHands.Hands()       #getting hand instances\n",
    "mpDraw = mp.solutions.drawing_utils #drawing landmarks\n",
    "pTime = 0                            #previous time\n",
    "cTime=0                              #current time\n",
    "\n",
    "while True:\n",
    "    success,img = cap.read(1)\n",
    "    imgRGB = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(imgRGB)\n",
    "#     print(results.multi_hand_landmarks)\n",
    "    if results.multi_hand_landmarks:\n",
    "        for handLms in results.multi_hand_landmarks:\n",
    "            for id,lm in enumerate(handLms.landmark):\n",
    "                h,w,c = img.shape\n",
    "                cx,cy = int(lm.x*w),int(lm.y*h)\n",
    "#                 print(id,cx,cy)\n",
    "                if id==8:\n",
    "                    cv2.circle(img,(cx,cy),15,(255,0,255),cv2.FILLED)\n",
    "                    x8 = cx\n",
    "                    y8 = cy\n",
    "                    \n",
    "                    #print(id,x8,y8)\n",
    "                if id==4:\n",
    "                    cv2.circle(img,(cx,cy),15,(255,0,255),cv2.FILLED)\n",
    "                    x4 = cx\n",
    "                    y4 = cy\n",
    "                    \n",
    "                    #print(id,x4,y4)\n",
    "                    \n",
    "\n",
    "                    \n",
    "            mpDraw.draw_landmarks(img,handLms,mpHands.HAND_CONNECTIONS)\n",
    "            cv2.line(img,(x8,y8),(x4,y4),(255,0,255),5)\n",
    "            distance = ((x4-x8)+(y4-y8))\n",
    "            volume.SetMasterVolumeLevel(-20.0, None)\n",
    "    cTime = time.time()\n",
    "    fps = int(1/(cTime-pTime))\n",
    "    pTime = cTime\n",
    "    \n",
    "    cv2.putText(img,str(distance),(10,70),cv2.FONT_HERSHEY_PLAIN,3,(255,0,255),3)\n",
    "#     img = cv2.flip(img,1)  \n",
    "    cv2.imshow(\"Image\",img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "          break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dbda8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pycaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b42bb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ctypes import cast, POINTER\n",
    "from comtypes import CLSCTX_ALL\n",
    "from pycaw.pycaw import AudioUtilities, IAudioEndpointVolume\n",
    "devices = AudioUtilities.GetSpeakers()\n",
    "interface = devices.Activate(IAudioEndpointVolume._iid_, CLSCTX_ALL, None)\n",
    "volume = cast(interface, POINTER(IAudioEndpointVolume))\n",
    "volume.GetMute()\n",
    "volume.GetMasterVolumeLevel()\n",
    "volume.GetVolumeRange()\n",
    "volume.SetMasterVolumeLevel(-20.0, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc62e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "mpHands = mp.solutions.hands  #palm detection using mediapipe\n",
    "hands = mpHands.Hands()       #getting hand instances\n",
    "mpDraw = mp.solutions.drawing_utils #drawing landmarks\n",
    "pTime = 0                            #previous time\n",
    "cTime=0                              #current time\n",
    "\n",
    "while True:\n",
    "    success,img = cap.read(1)\n",
    "    imgRGB = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(imgRGB)\n",
    "#     print(results.multi_hand_landmarks)\n",
    "    if results.multi_hand_landmarks:\n",
    "        for handLms in results.multi_hand_landmarks:\n",
    "            for id,lm in enumerate(handLms.landmark):\n",
    "                h,w,c = img.shape\n",
    "                cx,cy = int(lm.x*w),int(lm.y*h)\n",
    "#                 print(id,cx,cy)\n",
    "                if id==8:\n",
    "                    cv2.circle(img,(cx,cy),15,(255,0,255),cv2.FILLED)\n",
    "\n",
    "                    \n",
    "            mpDraw.draw_landmarks(img,handLms,mpHands.HAND_CONNECTIONS)\n",
    "    cTime = time.time()\n",
    "    fps = int(1/(cTime-pTime))\n",
    "    pTime = cTime\n",
    "    \n",
    "    cv2.putText(img,str(fps),(10,70),cv2.FONT_HERSHEY_PLAIN,3,(255,0,255),3)\n",
    "    img = cv2.flip(img,1)  \n",
    "    cv2.imshow(\"Image\",img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "          break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
